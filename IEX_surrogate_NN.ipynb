{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import torchTools as tt\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data was pickled as dictionary:\n",
    "#  y: list of 100k floats\n",
    "#  x: list 100k of 1-d, length 12 arrays\n",
    "\n",
    "input_fn = 'IEX_100k_04w.pkl'\n",
    "data = pickle.load(open(input_fn,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(data['y'], columns=['Rays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>24556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>28734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>71323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>7266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>58703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rays\n",
       "0      62184\n",
       "1       7104\n",
       "2      45266\n",
       "3      54623\n",
       "4      59044\n",
       "...      ...\n",
       "99995  24556\n",
       "99996  28734\n",
       "99997  71323\n",
       "99998   7266\n",
       "99999  58703\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_array = np.asarray(data['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(pos_array, columns=['oe1x','oe1xrot','oe2x','oe2xrot','oe3xrot','oe4xrot','oe5y','oe5xrot','oe5yrot','oe6y','oe6xrot','oe6yrot',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oe1x</th>\n",
       "      <th>oe1xrot</th>\n",
       "      <th>oe2x</th>\n",
       "      <th>oe2xrot</th>\n",
       "      <th>oe3xrot</th>\n",
       "      <th>oe4xrot</th>\n",
       "      <th>oe5y</th>\n",
       "      <th>oe5xrot</th>\n",
       "      <th>oe5yrot</th>\n",
       "      <th>oe6y</th>\n",
       "      <th>oe6xrot</th>\n",
       "      <th>oe6yrot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.145288</td>\n",
       "      <td>-0.003274</td>\n",
       "      <td>0.821222</td>\n",
       "      <td>-0.003335</td>\n",
       "      <td>-0.007931</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>-3.347656</td>\n",
       "      <td>-0.021918</td>\n",
       "      <td>-0.952138</td>\n",
       "      <td>2.523249</td>\n",
       "      <td>-0.127230</td>\n",
       "      <td>3.315194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.411249</td>\n",
       "      <td>0.003729</td>\n",
       "      <td>-5.429093</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>-4.538017</td>\n",
       "      <td>-0.055280</td>\n",
       "      <td>1.166162</td>\n",
       "      <td>0.521393</td>\n",
       "      <td>0.374672</td>\n",
       "      <td>-0.661753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.357904</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-2.747643</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>-15.492510</td>\n",
       "      <td>0.144513</td>\n",
       "      <td>-0.371621</td>\n",
       "      <td>-3.498419</td>\n",
       "      <td>0.483969</td>\n",
       "      <td>-3.284848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.110999</td>\n",
       "      <td>-0.003396</td>\n",
       "      <td>6.899192</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>-0.000743</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>-1.696894</td>\n",
       "      <td>0.071932</td>\n",
       "      <td>1.044310</td>\n",
       "      <td>-24.371554</td>\n",
       "      <td>-0.454240</td>\n",
       "      <td>-1.104378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.923700</td>\n",
       "      <td>-0.003032</td>\n",
       "      <td>-7.884230</td>\n",
       "      <td>-0.002892</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>-0.002225</td>\n",
       "      <td>-9.871366</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>-0.244404</td>\n",
       "      <td>-22.337997</td>\n",
       "      <td>-0.238650</td>\n",
       "      <td>0.185081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>-6.728028</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>-1.973903</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.003835</td>\n",
       "      <td>1.070975</td>\n",
       "      <td>-0.110507</td>\n",
       "      <td>-1.268863</td>\n",
       "      <td>9.926393</td>\n",
       "      <td>-0.331580</td>\n",
       "      <td>2.667666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>-8.113090</td>\n",
       "      <td>-0.003090</td>\n",
       "      <td>-2.006627</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>8.972775</td>\n",
       "      <td>0.032224</td>\n",
       "      <td>1.093333</td>\n",
       "      <td>-2.819569</td>\n",
       "      <td>0.161554</td>\n",
       "      <td>1.279756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1.823646</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>-6.891175</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>4.534051</td>\n",
       "      <td>-0.147315</td>\n",
       "      <td>1.096939</td>\n",
       "      <td>30.148267</td>\n",
       "      <td>-0.279186</td>\n",
       "      <td>2.333936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>7.585150</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>1.837656</td>\n",
       "      <td>-0.002993</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>-13.230985</td>\n",
       "      <td>0.079037</td>\n",
       "      <td>0.926955</td>\n",
       "      <td>15.506456</td>\n",
       "      <td>0.226261</td>\n",
       "      <td>0.619541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>-4.074488</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>1.908186</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.002261</td>\n",
       "      <td>-16.298846</td>\n",
       "      <td>-0.053393</td>\n",
       "      <td>-0.455460</td>\n",
       "      <td>1.808443</td>\n",
       "      <td>-0.187590</td>\n",
       "      <td>3.018214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           oe1x   oe1xrot      oe2x   oe2xrot   oe3xrot   oe4xrot       oe5y  \\\n",
       "0      3.145288 -0.003274  0.821222 -0.003335 -0.007931  0.005732  -3.347656   \n",
       "1      0.411249  0.003729 -5.429093  0.001347  0.002716  0.004176  -4.538017   \n",
       "2      7.357904 -0.000461 -2.747643  0.001471 -0.001400  0.006020 -15.492510   \n",
       "3      7.110999 -0.003396  6.899192 -0.001306 -0.000743  0.002116  -1.696894   \n",
       "4      2.923700 -0.003032 -7.884230 -0.002892 -0.001618 -0.002225  -9.871366   \n",
       "...         ...       ...       ...       ...       ...       ...        ...   \n",
       "99995 -6.728028 -0.000503 -1.973903 -0.001687  0.000280 -0.003835   1.070975   \n",
       "99996 -8.113090 -0.003090 -2.006627  0.003374  0.003509 -0.003905   8.972775   \n",
       "99997  1.823646  0.001029 -6.891175  0.002488 -0.002090 -0.000343   4.534051   \n",
       "99998  7.585150  0.002862  1.837656 -0.002993  0.006108  0.002685 -13.230985   \n",
       "99999 -4.074488  0.002193  1.908186 -0.000657  0.000021 -0.002261 -16.298846   \n",
       "\n",
       "        oe5xrot   oe5yrot       oe6y   oe6xrot   oe6yrot  \n",
       "0     -0.021918 -0.952138   2.523249 -0.127230  3.315194  \n",
       "1     -0.055280  1.166162   0.521393  0.374672 -0.661753  \n",
       "2      0.144513 -0.371621  -3.498419  0.483969 -3.284848  \n",
       "3      0.071932  1.044310 -24.371554 -0.454240 -1.104378  \n",
       "4      0.001150 -0.244404 -22.337997 -0.238650  0.185081  \n",
       "...         ...       ...        ...       ...       ...  \n",
       "99995 -0.110507 -1.268863   9.926393 -0.331580  2.667666  \n",
       "99996  0.032224  1.093333  -2.819569  0.161554  1.279756  \n",
       "99997 -0.147315  1.096939  30.148267 -0.279186  2.333936  \n",
       "99998  0.079037  0.926955  15.506456  0.226261  0.619541  \n",
       "99999 -0.053393 -0.455460   1.808443 -0.187590  3.018214  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data -- needed to put all inputs on same \"scale\"\n",
    "# i.e. mean of 0 and variance of 1; typically this improves training performance\n",
    "scaling = StandardScaler()\n",
    "scaling.fit(X)\n",
    "scaled_X = scaling.fit_transform(X)\n",
    "scaled_X = pd.DataFrame(scaled_X, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fit can be used later on as well, when used on real data\n",
    "scaling_fn = input_fn.split('.')[0]+'_scaling.pkl'\n",
    "with open(scaling_fn, 'wb') as f:\n",
    "    pickle.dump(scaling, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_X, Y, test_size=0.2, random_state=1)\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model (this is a bigger model originally meant for a GPU\n",
    "# the hidden layers can be shrunk/trimmed.\n",
    "batch_size = 64\n",
    "hidden_sizes = [12, 12, 12]\n",
    "epochs = 100\n",
    "ep_update = 10\n",
    "learning_rate = 0.001\n",
    "l2p = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------------------------------------------\n",
      " |        Epoch         |  Training  | Validation |\n",
      " |    Total: 100        | Loss (MAE) | Loss (MAE) |\n",
      " --------------------------------------------------\n",
      " |          1           |  27146.8212|  26954.8637|\n",
      " |          10          |  15575.2769|  15468.9888|\n",
      " |          20          |  15448.8535|  15327.0479|\n",
      " |          30          |  15439.8211|  15314.1833|\n",
      " |          40          |  15364.2905|  15247.2804|\n",
      " |          50          |  15307.2376|  15197.5793|\n",
      " |          60          |  15272.9358|  15168.1065|\n",
      " |          70          |  15242.0128|  15140.6104|\n",
      " |          80          |  14958.0384|  14847.9091|\n",
      " |          90          |   5665.3677|   5669.5522|\n",
      " |         100          |   4814.8185|   4849.0191|\n",
      " --------------------------------------------------\n",
      "----------------------------------------\n",
      "Model fitting/training time using:  cpu\n",
      "Process time:     142.98\n",
      "Wall time:     132.23\n",
      "----------------------------------------\n",
      " |       Training Error |4814.818520|\n",
      " |     Validation Error |4849.019079|\n"
     ]
    }
   ],
   "source": [
    "# run the model; returns a dictionary {model, loss, metric} where loss and metric are after each epoch\n",
    "result = [tt.runNN(X_train, Y_train, X_validation, Y_validation\n",
    "                  , batch_size = batch_size, hidden_sizes=hidden_sizes\n",
    "                  , learning_rate=learning_rate, epochs=epochs\n",
    "                  , l2_penalty=l2p, update=ep_update)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------------------------------------------\n",
      " |        Epoch         |  Training  | Validation |\n",
      " |    Total: 100        | Loss (MAE) | Loss (MAE) |\n",
      " --------------------------------------------------\n",
      " |          1           |  15582.6936|  15457.0714|\n",
      " |          10          |  15197.1829|  15077.2711|\n",
      " |          20          |  15159.7236|  15043.6004|\n",
      " |          30          |   5751.5617|   5796.0736|\n",
      " |          40          |   2863.6325|   2864.5198|\n",
      " |          50          |   1872.4414|   1870.9556|\n",
      " |          60          |   1720.8346|   1734.6522|\n",
      " |          70          |   1625.5026|   1628.7602|\n",
      " |          80          |   1533.8083|   1537.0685|\n",
      " |          90          |   1548.4008|   1553.4842|\n",
      " |         100          |   1513.3751|   1520.4785|\n",
      " --------------------------------------------------\n",
      "----------------------------------------\n",
      "Model fitting/training time using:  cpu\n",
      "Process time:     142.18\n",
      "Wall time:     131.48\n",
      "----------------------------------------\n",
      " |       Training Error |1513.375059|\n",
      " |     Validation Error |1520.478535|\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "result.append(tt.runNN(X_train, Y_train, X_validation, Y_validation\n",
    "                      , batch_size = batch_size, hidden_sizes=hidden_sizes\n",
    "                      , learning_rate=learning_rate, epochs=epochs\n",
    "                      , l2_penalty=l2p, update=ep_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------------------------------------------\n",
      " |        Epoch         |  Training  | Validation |\n",
      " |    Total: 1000       | Loss (MAE) | Loss (MAE) |\n",
      " --------------------------------------------------\n",
      " |          1           |  15692.6583|  15572.2378|\n",
      " |          50          |   1697.0076|   1700.7191|\n",
      " |         100          |   1303.5281|   1306.3937|\n",
      " |         150          |   1202.1828|   1205.0284|\n",
      " |         200          |   1157.1407|   1152.5705|\n",
      " |         250          |   1166.9948|   1158.8980|\n",
      " |         300          |   1024.7923|   1024.0950|\n",
      " |         350          |   1022.7280|   1020.1418|\n",
      " |         400          |    994.3764|   1002.3698|\n",
      " |         450          |   1022.5131|   1030.8525|\n",
      " |         500          |   1019.5063|   1024.2207|\n",
      " |         550          |   1018.4588|   1021.3864|\n",
      " |         600          |   1139.7759|   1145.2688|\n",
      " |         650          |    967.0600|    969.3868|\n",
      " |         700          |    921.2541|    930.4922|\n",
      " |         750          |    974.8217|    978.9074|\n",
      " |         800          |    898.8918|    907.9279|\n",
      " |         850          |    907.6319|    920.5353|\n",
      " |         900          |    776.6907|    784.5969|\n",
      " |         950          |    781.6734|    792.7863|\n",
      " |         1000         |    732.4405|    743.8309|\n",
      " --------------------------------------------------\n",
      "----------------------------------------\n",
      "Model fitting/training time using:  cpu\n",
      "Process time:    1328.79\n",
      "Wall time:    1232.31\n",
      "----------------------------------------\n",
      " |       Training Error |732.440486|\n",
      " |     Validation Error |743.830853|\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "ep_update = 50\n",
    "result.append(tt.runNN(X_train, Y_train, X_validation, Y_validation\n",
    "                      , batch_size = batch_size, hidden_sizes=hidden_sizes\n",
    "                      , learning_rate=learning_rate, epochs=epochs\n",
    "                      , l2_penalty=l2p, update=ep_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLModel(\n",
       "  (inputLayer): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (hiddenLayers): ModuleList(\n",
       "    (0): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (1): Linear(in_features=12, out_features=12, bias=True)\n",
       "  )\n",
       "  (outputLayer): Linear(in_features=12, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------------------------------------------\n",
      " |        Epoch         |  Training  | Validation |\n",
      " |    Total: 10000      | Loss (MAE) | Loss (MAE) |\n",
      " --------------------------------------------------\n",
      " |          1           |    777.7997|    784.1581|\n",
      " |         100          |    744.7823|    755.9467|\n",
      " |         200          |    664.9590|    676.8708|\n",
      " |         300          |    635.3205|    642.7029|\n",
      " |         400          |    565.8607|    579.3564|\n",
      " |         500          |    565.9024|    571.9579|\n",
      " |         600          |    607.5283|    615.9776|\n",
      " |         700          |    547.7454|    554.6326|\n",
      " |         800          |    572.7269|    579.4066|\n",
      " |         900          |    559.7200|    561.5881|\n",
      " |         1000         |    539.0986|    540.0226|\n",
      " |         1100         |    641.0209|    641.3311|\n",
      " |         1200         |    521.7689|    523.9916|\n",
      " |         1300         |    533.5455|    539.0431|\n",
      " |         1400         |    519.3269|    519.9878|\n",
      " |         1500         |    565.7890|    571.6360|\n",
      " |         1600         |    517.3002|    522.9435|\n",
      " |         1700         |    577.4836|    582.8532|\n",
      " |         1800         |    574.6051|    581.2822|\n",
      " |         1900         |    533.8447|    534.5318|\n",
      " |         2000         |    548.4003|    551.6065|\n",
      " |         2100         |    562.2802|    572.2214|\n",
      " |         2200         |    515.0996|    523.4325|\n",
      " |         2300         |    578.3384|    578.6010|\n",
      " |         2400         |    524.1227|    527.5849|\n",
      " |         2500         |    510.5428|    516.6930|\n",
      " |         2600         |    510.7695|    516.7830|\n",
      " |         2700         |    518.8985|    525.3445|\n",
      " |         2800         |    586.5415|    587.4883|\n",
      " |         2900         |    506.9519|    511.7621|\n",
      " |         3000         |    503.5865|    509.3549|\n",
      " |         3100         |    522.8921|    527.4865|\n",
      " |         3200         |    540.0368|    541.8275|\n",
      " |         3300         |    501.6708|    506.6714|\n",
      " |         3400         |    496.3963|    502.4954|\n",
      " |         3500         |    505.9247|    511.0069|\n",
      " |         3600         |    529.4242|    532.7266|\n",
      " |         3700         |    502.2547|    505.3924|\n",
      " |         3800         |    524.0650|    524.1797|\n",
      " |         3900         |    621.3258|    631.2595|\n",
      " |         4000         |    554.1181|    556.1667|\n",
      " |         4100         |    514.5007|    516.8434|\n",
      " |         4200         |    517.8485|    518.9870|\n",
      " |         4300         |    538.3073|    542.7774|\n",
      " |         4400         |    543.3306|    551.6433|\n",
      " |         4500         |    504.5245|    508.7275|\n",
      " |         4600         |    527.9938|    537.0567|\n",
      " |         4700         |    511.1809|    516.1231|\n",
      " |         4800         |    512.3083|    515.6989|\n",
      " |         4900         |    509.9874|    516.4584|\n",
      " |         5000         |    509.1173|    512.9520|\n",
      " |         5100         |    553.3291|    554.3228|\n",
      " |         5200         |    551.8028|    556.5698|\n",
      " |         5300         |    516.8166|    516.8835|\n",
      " |         5400         |    541.1321|    546.4967|\n",
      " |         5500         |    510.4592|    511.0759|\n",
      " |         5600         |    513.8706|    517.9440|\n",
      " |         5700         |    508.8748|    512.5662|\n",
      " |         5800         |    579.6137|    576.4635|\n",
      " |         5900         |    506.2670|    511.7606|\n",
      " |         6000         |    495.6573|    499.7464|\n",
      " |         6100         |    486.1541|    488.8509|\n",
      " |         6200         |    526.6709|    531.2676|\n",
      " |         6300         |    493.9912|    499.8763|\n",
      " |         6400         |    485.1498|    491.8092|\n",
      " |         6500         |    519.2661|    525.1899|\n",
      " |         6600         |    497.4039|    498.8093|\n",
      " |         6700         |    480.0514|    482.0747|\n",
      " |         6800         |    570.3577|    569.5903|\n",
      " |         6900         |    479.8153|    485.7923|\n",
      " |         7000         |    486.7514|    490.6952|\n",
      " |         7100         |    479.2909|    484.6049|\n",
      " |         7200         |    535.1708|    535.1557|\n",
      " |         7300         |    481.2910|    482.6122|\n",
      " |         7400         |    513.5667|    516.7828|\n",
      " |         7500         |    480.7914|    481.6875|\n",
      " |         7600         |    470.8242|    472.7104|\n",
      " |         7700         |    486.0159|    488.5633|\n",
      " |         7800         |    530.0355|    529.9068|\n",
      " |         7900         |    515.7543|    518.0409|\n",
      " |         8000         |    483.8068|    486.2744|\n",
      " |         8100         |    491.3299|    494.7273|\n",
      " |         8200         |    466.6338|    467.3093|\n",
      " |         8300         |    469.3924|    470.9781|\n",
      " |         8400         |    474.5332|    478.8680|\n",
      " |         8500         |    499.3971|    501.5004|\n",
      " |         8600         |    525.1404|    525.9288|\n",
      " |         8700         |    488.4792|    491.8857|\n",
      " |         8800         |    475.1015|    477.5631|\n",
      " |         8900         |    537.3609|    534.8959|\n",
      " |         9000         |    489.7552|    490.5620|\n",
      " |         9100         |    479.4459|    482.2017|\n",
      " |         9200         |    516.1423|    519.9853|\n",
      " |         9300         |    486.7093|    488.2792|\n",
      " |         9400         |    485.7365|    487.4465|\n",
      " |         9500         |    471.2776|    472.1132|\n",
      " |         9600         |    482.8374|    487.3708|\n",
      " |         9700         |    487.3445|    491.9828|\n",
      " |         9800         |    482.9747|    486.3661|\n",
      " |         9900         |    473.2287|    473.1397|\n",
      " |        10000         |    478.3531|    482.1287|\n",
      " --------------------------------------------------\n",
      "----------------------------------------\n",
      "Model fitting/training time using:  cpu\n",
      "Process time:   13090.08\n",
      "Wall time:   12143.58\n",
      "----------------------------------------\n",
      " |       Training Error |478.353135|\n",
      " |     Validation Error |482.128717|\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 10000\n",
    "ep_update = 100\n",
    "result.append(tt.runNN(X_train, Y_train, X_validation, Y_validation\n",
    "                      , batch_size = batch_size, hidden_sizes=hidden_sizes\n",
    "                      , learning_rate=learning_rate, epochs=epochs\n",
    "                      , l2_penalty=l2p, update=ep_update, model = result[2]['model']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------------------------------------------\n",
      " |        Epoch         |  Training  | Validation |\n",
      " |    Total: 10000      | Loss (MAE) | Loss (MAE) |\n",
      " --------------------------------------------------\n",
      " |          1           |    449.5347|    450.9754|\n",
      " |         100          |    456.7406|    459.1124|\n",
      " |         200          |    449.1531|    451.8044|\n",
      " |         300          |    447.3230|    448.4155|\n",
      " |         400          |    447.1481|    448.8587|\n",
      " |         500          |    451.2200|    453.1767|\n",
      " |         600          |    447.6492|    449.4134|\n",
      " |         700          |    456.0239|    458.3672|\n",
      " |         800          |    445.9797|    447.2624|\n",
      " |         900          |    450.0570|    452.6604|\n",
      " |         1000         |    446.0426|    447.4813|\n",
      " |         1100         |    445.8658|    448.2915|\n",
      " |         1200         |    446.3764|    447.4429|\n",
      " |         1300         |    446.2789|    447.9525|\n",
      " |         1400         |    448.3734|    448.8454|\n",
      " |         1500         |    453.8678|    455.8298|\n",
      " |         1600         |    445.5786|    447.2279|\n",
      " |         1700         |    456.4997|    458.5990|\n",
      " |         1800         |    445.8622|    447.4339|\n",
      " |         1900         |    452.4551|    454.3802|\n",
      " |         2000         |    460.6918|    462.6246|\n",
      " |         2100         |    446.7524|    448.5515|\n",
      " |         2200         |    446.9049|    448.8934|\n",
      " |         2300         |    447.2256|    449.1514|\n",
      " |         2400         |    446.9614|    448.9937|\n",
      " |         2500         |    446.3971|    447.6124|\n",
      " |         2600         |    452.0380|    454.2475|\n",
      " |         2700         |    446.9051|    447.7315|\n",
      " |         2800         |    448.1385|    448.8506|\n",
      " |         2900         |    446.8863|    448.6122|\n",
      " |         3000         |    447.5558|    449.1351|\n",
      " |         3100         |    453.5247|    455.4461|\n",
      " |         3200         |    449.6655|    451.6557|\n",
      " |         3300         |    445.2821|    447.0990|\n",
      " |         3400         |    447.8670|    449.1829|\n",
      " |         3500         |    446.8869|    447.7080|\n",
      " |         3600         |    449.3585|    449.8122|\n",
      " |         3700         |    446.1347|    447.7393|\n",
      " |         3800         |    448.6516|    450.1100|\n",
      " |         3900         |    449.4203|    451.8335|\n",
      " |         4000         |    448.6840|    450.6492|\n",
      " |         4100         |    448.3789|    450.1821|\n",
      " |         4200         |    451.8663|    453.9417|\n",
      " |         4300         |    448.0701|    451.0971|\n",
      " |         4400         |    448.3153|    449.8858|\n",
      " |         4500         |    451.0612|    453.1486|\n",
      " |         4600         |    451.0070|    453.2263|\n",
      " |         4700         |    458.3229|    460.4507|\n",
      " |         4800         |    449.5772|    451.6251|\n",
      " |         4900         |    446.0475|    447.7326|\n",
      " |         5000         |    462.3411|    464.4644|\n",
      " |         5100         |    448.6902|    451.5962|\n",
      " |         5200         |    447.8352|    450.1356|\n",
      " |         5300         |    448.6934|    451.0505|\n",
      " |         5400         |    445.7139|    448.2067|\n",
      " |         5500         |    446.5680|    448.5381|\n",
      " |         5600         |    453.3141|    454.4176|\n",
      " |         5700         |    446.9512|    448.0000|\n",
      " |         5800         |    446.0199|    447.2760|\n",
      " |         5900         |    444.8982|    446.5565|\n",
      " |         6000         |    445.2732|    446.8832|\n",
      " |         6100         |    455.9956|    458.1478|\n",
      " |         6200         |    446.1582|    448.6891|\n",
      " |         6300         |    446.3717|    448.4834|\n",
      " |         6400         |    445.9640|    447.9143|\n",
      " |         6500         |    446.0086|    448.0747|\n",
      " |         6600         |    447.4298|    448.1154|\n",
      " |         6700         |    446.5376|    447.8902|\n",
      " |         6800         |    445.7687|    447.5517|\n",
      " |         6900         |    449.6628|    452.0236|\n",
      " |         7000         |    446.1785|    447.8040|\n",
      " |         7100         |    445.2065|    447.7465|\n",
      " |         7200         |    445.0632|    446.7862|\n",
      " |         7300         |    446.3861|    446.9440|\n",
      " |         7400         |    447.2960|    449.1360|\n",
      " |         7500         |    445.4420|    447.9170|\n",
      " |         7600         |    459.7043|    462.2615|\n",
      " |         7700         |    454.5807|    456.3956|\n",
      " |         7800         |    445.6749|    448.4213|\n",
      " |         7900         |    458.0397|    460.3777|\n",
      " |         8000         |    447.3333|    448.5113|\n",
      " |         8100         |    446.6422|    448.7106|\n",
      " |         8200         |    446.2423|    448.0993|\n",
      " |         8300         |    446.1965|    447.4635|\n",
      " |         8400         |    452.3783|    455.0065|\n",
      " |         8500         |    447.3350|    447.8962|\n",
      " |         8600         |    446.6794|    447.8415|\n",
      " |         8700         |    449.6587|    450.7801|\n",
      " |         8800         |    452.2796|    455.3221|\n",
      " |         8900         |    445.3712|    447.8099|\n",
      " |         9000         |    447.0807|    448.8162|\n",
      " |         9100         |    445.6595|    447.7395|\n",
      " |         9200         |    454.2523|    457.0957|\n",
      " |         9300         |    447.3574|    448.8688|\n",
      " |         9400         |    451.3700|    453.5484|\n",
      " |         9500         |    445.9937|    448.3237|\n",
      " |         9600         |    455.9713|    458.1973|\n",
      " |         9700         |    445.7902|    448.1822|\n",
      " |         9800         |    451.5151|    453.8700|\n",
      " |         9900         |    446.1739|    448.9336|\n",
      " |        10000         |    445.2282|    447.3717|\n",
      " --------------------------------------------------\n",
      "----------------------------------------\n",
      "Model fitting/training time using:  cpu\n",
      "Process time:   13137.48\n",
      "Wall time:   12186.53\n",
      "----------------------------------------\n",
      " |       Training Error |445.228218|\n",
      " |     Validation Error |447.371659|\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 10000\n",
    "ep_update = 100\n",
    "result.append(tt.runNN(X_train, Y_train, X_validation, Y_validation\n",
    "                      , batch_size = batch_size, hidden_sizes=hidden_sizes\n",
    "                      , learning_rate=learning_rate, epochs=epochs\n",
    "                      , l2_penalty=l2p, update=ep_update, model = result[3]['model']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beams/MWYMAN/.conda/envs/shadow/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Saving the model to be used in timing tests aginst\n",
    "nn_fn = input_fn.split('.')[0]+'_NN_results.pkl'\n",
    "with open(nn_fn, 'wb') as f:\n",
    "    pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test error\n",
    "Need code to run on test set -- need to ensure conversion to correct data type for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model\n",
    "nn_fn = input_fn.split('.')[0]+'_NN_results.pkl'\n",
    "with open(nn_fn, 'rb') as f:\n",
    "    result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeatures = torch.tensor(X_test.values)\n",
    "testTargets = torch.tensor(Y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLModel(\n",
       "  (inputLayer): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (hiddenLayers): ModuleList(\n",
       "    (0): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (1): Linear(in_features=12, out_features=12, bias=True)\n",
       "  )\n",
       "  (outputLayer): Linear(in_features=12, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = result[4]['model']\n",
    "device = torch.device('cpu')\n",
    "tt.to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |           Test Error |454.971124|\n"
     ]
    }
   ],
   "source": [
    "# get test scores\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "testPredictions = model(tt.to_device(testFeatures.float(), device))\n",
    "lformat = ' |{0:>22}|{1:>10.6f}|'\n",
    "print(lformat.format('Test Error ', mean_absolute_error(Y_test, testPredictions.cpu().detach().numpy(), )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots - comparing surrogate model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        Tensor\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "tensor([[71315.8438],\n",
       "        [46672.1133],\n",
       "        [37974.1562],\n",
       "        ...,\n",
       "        [22540.0430],\n",
       "        [49414.3125],\n",
       "        [72397.0859]], grad_fn=<AddmmBackward>)\n",
       "\u001b[0;31mLength:\u001b[0m      20000\n",
       "\u001b[0;31mFile:\u001b[0m        ~/.conda/envs/shadow/lib/python3.7/site-packages/torch/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m   <no docstring>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testPredictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredarr = testPredictions.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71315.84 ],\n",
       "       [46672.113],\n",
       "       [37974.156],\n",
       "       ...,\n",
       "       [22540.043],\n",
       "       [49414.312],\n",
       "       [72397.086]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43660</th>\n",
       "      <td>71890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87278</th>\n",
       "      <td>46394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14317</th>\n",
       "      <td>38067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81932</th>\n",
       "      <td>21117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95321</th>\n",
       "      <td>17806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73441</th>\n",
       "      <td>56761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>62984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71987</th>\n",
       "      <td>22545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26910</th>\n",
       "      <td>49185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24890</th>\n",
       "      <td>72753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rays\n",
       "43660  71890\n",
       "87278  46394\n",
       "14317  38067\n",
       "81932  21117\n",
       "95321  17806\n",
       "...      ...\n",
       "73441  56761\n",
       "1341   62984\n",
       "71987  22545\n",
       "26910  49185\n",
       "24890  72753\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71890, 46394, 38067, ..., 22545, 49185, 72753])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(Y_test.Rays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fe89cdb4ab42cbb4c9c19f45ab2473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd81e58a250>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testPredictions vs Y_test\n",
    "fig, axs = plt.subplots(1, 1, tight_layout=True)\n",
    "axs.set(title = '',\n",
    "        xlabel = 'Shadow Data',\n",
    "        ylabel = 'NN predictions')\n",
    "axs.plot(np.asarray(Y_test.Rays), testPredarr, marker = '.', linestyle = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 730.,  801.,  772.,  873.,  919.,  918., 1027., 1049., 1121.,\n",
       "        1172., 1282., 1424., 1435., 1368., 1147., 1142.,  992.,  851.,\n",
       "         647.,  330.]),\n",
       " array([  143.  ,  4302.25,  8461.5 , 12620.75, 16780.  , 20939.25,\n",
       "        25098.5 , 29257.75, 33417.  , 37576.25, 41735.5 , 45894.75,\n",
       "        50054.  , 54213.25, 58372.5 , 62531.75, 66691.  , 70850.25,\n",
       "        75009.5 , 79168.75, 83328.  ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for both testPredictions and Y_test\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, tight_layout=True)\n",
    "\n",
    "axs.hist(np.asarray(Y_test.Rays), bins = 20, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fa00c12ae50>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = Y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison['pred'] = testPredarr.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rays</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43660</th>\n",
       "      <td>71890</td>\n",
       "      <td>71315.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87278</th>\n",
       "      <td>46394</td>\n",
       "      <td>46672.113281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14317</th>\n",
       "      <td>38067</td>\n",
       "      <td>37974.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81932</th>\n",
       "      <td>21117</td>\n",
       "      <td>20883.498047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95321</th>\n",
       "      <td>17806</td>\n",
       "      <td>17595.228516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73441</th>\n",
       "      <td>56761</td>\n",
       "      <td>57992.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>62984</td>\n",
       "      <td>62893.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71987</th>\n",
       "      <td>22545</td>\n",
       "      <td>22540.042969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26910</th>\n",
       "      <td>49185</td>\n",
       "      <td>49414.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24890</th>\n",
       "      <td>72753</td>\n",
       "      <td>72397.085938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rays          pred\n",
       "43660  71890  71315.843750\n",
       "87278  46394  46672.113281\n",
       "14317  38067  37974.156250\n",
       "81932  21117  20883.498047\n",
       "95321  17806  17595.228516\n",
       "...      ...           ...\n",
       "73441  56761  57992.882812\n",
       "1341   62984  62893.617188\n",
       "71987  22545  22540.042969\n",
       "26910  49185  49414.312500\n",
       "24890  72753  72397.085938\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fa00c3b7990>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa00c4ba490>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
